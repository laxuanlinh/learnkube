## Why?
- Moving from monolith to microservice architecture
- The need to deploy multiple smaller services and managing them using custom scripts are very difficult
- The need to have a technology to manage containerized services

## Features
- High availability or no downtime
- Scalability, can scale fast
- Disaster recovery

## Architecture
- Each cluster has at least 1 `master node` and multiple `worker nodes`
- Each `worker node` has a Kubelet process running, this is to command them to execute tasks like running the application
- There are multiple containers running one each `worker node`
- On `master node`, there are processes running to manage the cluster
- One of the processes is an `API server` which is an entry point to the cluster
- This API could also be a UI or CLI
- `Master node` also includes `Controller Manager` to keep track of what's happening
- A `scheduler` to ensure pod's placement
- `etcd` is a key value backing store to keep the state of the cluster
- All nodes communicate via a `Virtual Network`
- Usually worker nodes have much more resources than master nodes because they have to handle more load.
- But the `master nodes` are more important or else we cannot access the cluster, so in PROD environment, we usually have 2 `master nodes`

## Main components

### Node and Pod
- A cluster has many `Nodes`
- Each `Node` has many `Pods`
- `Pod` is the smallest unit in Kube
- Each `pod` is an abstraction of the container inside. 
- The reason for having a `pod` instead of the container is because Kube wants to abstract the containerize technology in case it's changed and also we don't have to work with Docker and only with Kube
- `Pod` is usually meant to run only `1` application per pod
- Each pod gets its own `IP address` and they can communicate with their internal `IP addresses`
- If a pod dies and a new node is created to replace, a new `IP address` is assigned, this might be difficult to reconnect

### Service and Ingress
- `Service` is a static permanent `IP address` attached to each `pod`
- `Serivces` don't share the same lifecycle with `Pods`, even if the Pod dies, the `Service` and the `IP address` stay
- There are 2 kinds of services:
    - `Internal service`: for internal components that we don't want to expose like DB
    - `External service`: as the entry to the cluster
- `Ingress` is another component to forward requests to `IP addresses`, it's a collection of routing rules, also helps to make URL more readable.

### Config Map
- When we need to update the Database, all other services also have to update their URL to the database and rebuild the image.
- `Config map` is an external configuration that pods connect to and pull config.
- So we just need to update the URL in the `Config map`

### Secret
- Secret is similar to ConfigMap but to store secret in base64 format
- However Base64 is not encryption so it's meant to be ecnrypted using third party as Kubernetes doesn't provide encryption

### Volume
- Long term physical storage attached to a `pod` so that when a pod dies, the data doesn't disappear 
- Volumnes are not part of a Cluster but simply either a local storage or remote cloud storage because Kubernetes doesn't manage data persistence

### Blueprint and Deployment
- To increase the availability, we don't just have 1 `node` but multiple `nodes` where `pods` connecting to the same `service`
- To do this, instead of manually replicating the `node`, we have a config file called `Blueprint` where we can specify how many replicas we want
- The process to deploy the `blueprint` is called a `Deployment`.
- We don't usually work with nodes and pods in Kubernetes but mostly with `Blueprints` and `Deployments`
- However we can't replicate databases using `Deployments` because they're stateful and there has to be a mechanism to manage who is writing and who is reading to the shared data storage

### Statefulset
- This is component to deploy stateful applications like databases
- Statefulset manages the deployment and replication of database and the synchronization of the replicas
- However it's more difficult to deploy databases using Statefulset so it's also a common practice to host databases outside of Kubernetes

## Configuration
- We can interact with Kube clusters using either API, dashboard or CLI
- The request to Kube has to be in JSON or YAML format
- Every config file has 3 parts:
    - `metadata`: like name
    - `spec`: specficiations of the pods
    - `status`: automatically generated by Kube to check whether the current state is up to the desired state. The state of applications is fetched from `etcd` process on `master node`

## Minikube
- It's a small VM to run a simple Kube cluster that has only 1 node that plays the role of both master and worker node
- Docker is pre-installed

## kubectl
- It's a CLI tool to interact with `API server` of a cluster

## Demo

### Step 1: Create ConfigMap and Secret
- Create a file name `mongo-config.yml` as a Config Map, in data section, specify the key/value `mongo-url: mongo-service`.
- Create a file name `mongo-secret.yml` as a Secret, in data section, specify key/value pairs username and password in Base64 format.

### Step 2: Create Mongo and Webapp service Deployment file
- Create a deployment file `mongo-service.yml`.
- In the spec section, we can give how many pod replicas there are.
- In the `template` > `spec` section, we can specify the name of the container, its image and ports, in this case the container's name is `mongodb`, `image` is `mongo:5.0` and `containerPort` by default is `27017`
- In `metadata` section of any component, we can give a `label`, when a deployment is running, each pod replica is given a unique name, so to refer to all of them, we can use labels are additional identifier, for pod it's mandatory but optional for other components
- Kubernetes identifies which pod replicas belong to which deployment by the `selector` > `matchLabels`.
- To create a service, we need to define the service name in the `metadata` section which matches the service name in Config Map.
- For the servie to know which pods it forward traffic to, we need to give the `spec` > `selector` the same name as the pod label
- For service ports, we specify the service's port and `targetPort` which is the same port as the container's port.
- It's also a common practice to have `port` the same as `targetPort` to make things simple.
- We also duplicate the mongodb file into a webapp service file with same config except for the image and port
- To fetch username and password from secret file, we need to define the environment variables using `env`.
- The environment variables we have to set, according to the Mongo image documentation are `MONGO_INITDB_ROOT_USERNAME` and `MONGO_INITDB_ROOT_PASSWORD`, we can either directly set them using `value` or we can use `valueFrom` > `secretKeyRef` to fetch from the `mongo-secret` file
- We need to do the same thing for the webapp file with 3 environment variables `USER_NAME`, `USER_PWD` and `DB_URL`. Since the DB_URL is not from secret but from the config map, we need to use `valueFrom` > `configMapRefKey` instead.
- To expose the webapp, we need an `external service`, by default the type of a service is `ClusterIP`, to expose this webapps service, we need to change its type to `NodePort` and add another port called `nodePort`.
- The `nodePort` is the port which the node exposes the service and it has to be in range of `30000-32767`

### Deploy
- To deploy a `Deployment`, the `Secret` and `ConfigMap` file have to exist beforehand
```zsh
laxuanlinh@Las-MacBook-Air demo % kubectl apply -f mongo-config.yml
configmap/mongo-config created

laxuanlinh@Las-MacBook-Air demo % kubectl apply -f mongo-secret.yml
secret/mongo-secret created
```
- Then we can create deployment for mongo and webapp
```zsh
laxuanlinh@Las-MacBook-Air demo % kubectl apply -f mongo.yml
deployment.apps/mongo-deployment created
service/mongo-service created

laxuanlinh@Las-MacBook-Air demo % kubectl apply -f webapp.yml
deployment.apps/webapp-deployment created
service/webapp-service created
```

- Now we can check on the pods running 
```zsh
laxuanlinh@Las-MacBook-Air demo % kubectl get pod
NAME                                READY   STATUS    RESTARTS   AGE
mongo-deployment-85d45f7888-nw722   1/1     Running   0          7m48s
webapp-deployment-8688fdddf-gvr7h   1/1     Running   0          25s
```
- To get config map and secret
```zsh
laxuanlinh@Las-MacBook-Air demo % kubectl get configmap
NAME               DATA   AGE
kube-root-ca.crt   1      7d22h
mongo-config       1      11m
laxuanlinh@Las-MacBook-Air demo % kubectl get secret
NAME           TYPE     DATA   AGE
mongo-secret   Opaque   2      11m
```

- To get details about a pod
```zsh
kubectl describe pod mongo-deployment-85d45f7888-nw722
```
- To get logs from a pod
```zsh
laxuanlinh@Las-MacBook-Air demo % kubectl logs webapp-deployment-8688fdddf-gvr7h
app listening on port 3000!
```

- To stream a log, we add -f option
```zsh
laxuanlinh@Las-MacBook-Air demo % kubectl logs -f webapp-deployment-8688fdddf-gvr7h
```

### Access the service
- To access the services on a node, we need to get the node IP address and the `NodePort` service's port
- To get node's IP
```zsh
laxuanlinh@Las-MacBook-Air demo % kubectl get node -o wide         
NAME       STATUS   ROLES           AGE     VERSION   INTERNAL-IP    EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION        CONTAINER-RUNTIME
minikube   Ready    control-plane   7d22h   v1.27.4   192.168.49.2   <none>        Ubuntu 22.04.2 LTS   5.15.49-linuxkit-pr   docker://24.0.4
```
- To get the services
```zsh
laxuanlinh@Las-MacBook-Air demo % kubectl get service
NAME             TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
kubernetes       ClusterIP   10.96.0.1        <none>        443/TCP          7d22h
mongo-service    ClusterIP   10.106.143.116   <none>        27017/TCP        20m
webapp-service   NodePort    10.97.146.76     <none>        3000:30000/TCP   15m
```

- Now we can access the service using node's internal IP and `NodePort`'s port.
- However if we're runnign docker on MacOS with Darwin kernel or Windows, the IP address is limited and cannot be accessed
- To expose the IP address, we need to run a process with the following command to tunnel to the cluster
```zsh
minikube services webapp-service
```
