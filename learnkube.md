## Why?
- Moving from monolith to microservice architecture
- The need to deploy multiple smaller services and managing them using custom scripts are very difficult
- The need to have a technology to manage containerized services

## Features
- High availability or no downtime
- Scalability, can scale fast
- Disaster recovery

## Architecture
- Each cluster has at least 1 `master node` and multiple `worker nodes`
- Each `worker node` has a Kubelet process running, this is to command them to execute tasks like running the application
- There are multiple containers running one each `worker node`
- On `master node`, there are processes running to manage the cluster
- One of the processes is an `API server` which is an entry point to the cluster
- This API could also be a UI or CLI
- `Master node` also includes `Controller Manager` to keep track of what's happening
- A `scheduler` to ensure pod's placement
- `etcd` is a key value backing store to keep the state of the cluster
- All nodes communicate via a `Virtual Network`
- Usually worker nodes have much more resources than master nodes because they have to handle more load.
- But the `master nodes` are more important or else we cannot access the cluster, so in PROD environment, we usually have 2 `master nodes`

## Main components

### Node and Pod
- A cluster has many `Nodes`
- Each `Node` has many `Pods`
- `Pod` is the smallest unit in Kube
- Each `pod` is an abstraction of the container inside. 
- The reason for having a `pod` instead of the container is because Kube wants to abstract the containerize technology in case it's changed and also we don't have to work with Docker and only with Kube
- `Pod` is usually meant to run only `1` application per pod
- Each pod gets its own `IP address` and they can communicate with their internal `IP addresses`
- If a pod dies and a new node is created to replace, a new `IP address` is assigned, this might be difficult to reconnect

### Service and Ingress
- `Service` is a static permanent `IP address` attached to each `pod`
- `Serivces` don't share the same lifecycle with `Pods`, even if the Pod dies, the `Service` and the `IP address` stay
- There are 2 kinds of services:
    - `Internal service`: for internal components that we don't want to expose like DB
    - `External service`: as the entry to the cluster
- `Ingress` is another component to forward requests to `IP addresses`, it's a collection of routing rules, also helps to make URL more readable.

### Config Map
- When we need to update the Database, all other services also have to update their URL to the database and rebuild the image.
- `Config map` is an external configuration that pods connect to and pull config.
- So we just need to update the URL in the `Config map`

### Secret
- Secret is similar to ConfigMap but to store secret in base64 format
- However Base64 is not encryption so it's meant to be ecnrypted using third party as Kubernetes doesn't provide encryption

### Volume
- Long term physical storage attached to a `pod` so that when a pod dies, the data doesn't disappear 
- Volumnes are not part of a Cluster but simply either a local storage or remote cloud storage because Kubernetes doesn't manage data persistence

## Blueprint and Deployment
- To increase the availability, we don't just have 1 `node` but multiple `nodes` where `pods` connecting to the same `service`
- To do this, instead of manually replicating the `node`, we have a config file called `Blueprint` where we can specify how many replicas we want
- The process to deploy the `blueprint` is called a `Deployment`.
- We don't usually work with nodes and pods in Kubernetes but mostly with `Blueprints` and `Deployments`
- However we can't replicate databases using `Deployments` because they're stateful and there has to be a mechanism to manage who is writing and who is reading to the shared data storage

### Statefulset
- This is component to deploy stateful applications like databases
- Statefulset manages the deployment and replication of database and the synchronization of the replicas
- However it's more difficult to deploy databases using Statefulset so it's also a common practice to host databases outside of Kubernetes


## Configuration
- We can interact with Kube clusters using either API, dashboard or CLI
- The request to Kube has to be in JSON or YAML format
- Every config file has 3 parts:
    - `metadata`: like name
    - `spec`: specficiations of the pods
    - `status`: automatically generated by Kube to check whether the current state is up to the desired state. The state of applications is fetched from `etcd` process on `master node`

## Minikube
- It's a small VM to run a simple Kube cluster that has only 1 node that plays the role of both master and worker node
- Docker is pre-installed

## kubectl
- It's a CLI tool to interact with `API server` of a cluster